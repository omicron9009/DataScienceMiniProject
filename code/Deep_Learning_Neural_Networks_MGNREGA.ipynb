{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Learning Neural Network Models for MGNREGA Wage Prediction\n",
        "\n",
        "This notebook implements various neural network architectures to predict wages based on MGNREGA dataset features.\n",
        "\n",
        "## Models Covered:\n",
        "1. **Simple Feedforward Neural Network (Dense layers)**\n",
        "2. **Deep Neural Network (Multiple hidden layers)**\n",
        "3. **LSTM (Long Short-Term Memory) for sequential patterns**\n",
        "4. **Comparison and Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "Traceback (most recent call last):\n  File \"c:\\Users\\jadit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jadit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
            "\u001b[31mImportError\u001b[39m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score, mean_absolute_error\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Deep Learning imports\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jadit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jadit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[39m\n\u001b[32m     86\u001b[39m     sys.setdlopenflags(_default_dlopen_flags)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     89\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback.format_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     90\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     91\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     92\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     93\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mIf you need help, create an issue \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     94\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     95\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mand include the entire stack trace above this error message.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
            "\u001b[31mImportError\u001b[39m: Traceback (most recent call last):\n  File \"c:\\Users\\jadit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# Deep Learning imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Reshape\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load and Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "# IMPORTANT: Replace the path below with your actual CSV file path\n",
        "df = pd.read_csv('..\\\\data\\\\combined.csv')  # Update this path!\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Selection - Using features from your regression analysis\n",
        "# Based on your previous analysis, these were the important features\n",
        "\n",
        "feature_columns = [\n",
        "    'Total_Exp',\n",
        "    'Approved_Labour_Budget',\n",
        "    'Women_Persondays',\n",
        "    'Persondays_of_Central_Liability_so_far',\n",
        "    'Total_Households_Worked',\n",
        "    'Total_Individuals_Worked',\n",
        "    'Number_of_Completed_Works',\n",
        "    'Number_of_Ongoing_Works'\n",
        "]\n",
        "\n",
        "target_column = 'Wages'\n",
        "\n",
        "# Create feature matrix X and target vector y\n",
        "X = df[feature_columns].copy()\n",
        "y = df[target_column].copy()\n",
        "\n",
        "# Handle missing values\n",
        "X = X.fillna(X.median())\n",
        "y = y.fillna(y.median())\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Target vector shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Train-Test Split and Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into train and test sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n",
        "\n",
        "# Standardize features (important for neural networks)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train_scaled = np.array(X_train_scaled, dtype=np.float32)\n",
        "X_test_scaled = np.array(X_test_scaled, dtype=np.float32)\n",
        "y_train = np.array(y_train, dtype=np.float32)\n",
        "y_test = np.array(y_test, dtype=np.float32)\n",
        "\n",
        "print(f\"\\nFeature statistics after scaling:\")\n",
        "print(f\"Mean: {X_train_scaled.mean():.4f}\")\n",
        "print(f\"Std: {X_train_scaled.std():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 1: Simple Feedforward Neural Network (Baseline)\n",
        "\n",
        "This is a basic dense neural network with:\n",
        "- Input layer\n",
        "- Two hidden layers with ReLU activation\n",
        "- Output layer for regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build Simple Neural Network\n",
        "def build_simple_nn(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_dim=input_dim, name='hidden_1'),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu', name='hidden_2'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, name='output')  # Single output for regression\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='mean_squared_error',\n",
        "        metrics=['mae', 'mse']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "simple_nn = build_simple_nn(X_train_scaled.shape[1])\n",
        "\n",
        "# Display model architecture\n",
        "print(\"Simple Neural Network Architecture:\")\n",
        "simple_nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up callbacks\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=20,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=10,\n",
        "    min_lr=0.00001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training Simple Neural Network...\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "history_simple = simple_nn.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate Simple NN\n",
        "y_pred_simple = simple_nn.predict(X_test_scaled).flatten()\n",
        "\n",
        "mse_simple = mean_squared_error(y_test, y_pred_simple)\n",
        "rmse_simple = np.sqrt(mse_simple)\n",
        "mae_simple = mean_absolute_error(y_test, y_pred_simple)\n",
        "r2_simple = r2_score(y_test, y_pred_simple)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Simple Neural Network - Test Results\")\n",
        "print(\"=\"*50)\n",
        "print(f\"MSE: {mse_simple:,.2f}\")\n",
        "print(f\"RMSE: {rmse_simple:,.2f}\")\n",
        "print(f\"MAE: {mae_simple:,.2f}\")\n",
        "print(f\"R¬≤ Score: {r2_simple:.4f}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2: Deep Neural Network (More Layers)\n",
        "\n",
        "A deeper architecture with:\n",
        "- More hidden layers\n",
        "- Batch normalization\n",
        "- Dropout for regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "# Build Deep Neural Network\n",
        "def build_deep_nn(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_dim=input_dim, name='hidden_1'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        \n",
        "        Dense(64, activation='relu', name='hidden_2'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        \n",
        "        Dense(32, activation='relu', name='hidden_3'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        \n",
        "        Dense(16, activation='relu', name='hidden_4'),\n",
        "        Dropout(0.2),\n",
        "        \n",
        "        Dense(1, name='output')\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='mean_squared_error',\n",
        "        metrics=['mae', 'mse']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "deep_nn = build_deep_nn(X_train_scaled.shape[1])\n",
        "\n",
        "print(\"Deep Neural Network Architecture:\")\n",
        "deep_nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Deep NN\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training Deep Neural Network...\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "history_deep = deep_nn.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate Deep NN\n",
        "y_pred_deep = deep_nn.predict(X_test_scaled).flatten()\n",
        "\n",
        "mse_deep = mean_squared_error(y_test, y_pred_deep)\n",
        "rmse_deep = np.sqrt(mse_deep)\n",
        "mae_deep = mean_absolute_error(y_test, y_pred_deep)\n",
        "r2_deep = r2_score(y_test, y_pred_deep)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Deep Neural Network - Test Results\")\n",
        "print(\"=\"*50)\n",
        "print(f\"MSE: {mse_deep:,.2f}\")\n",
        "print(f\"RMSE: {rmse_deep:,.2f}\")\n",
        "print(f\"MAE: {mae_deep:,.2f}\")\n",
        "print(f\"R¬≤ Score: {r2_deep:.4f}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 3: LSTM Neural Network\n",
        "\n",
        "LSTM (Long Short-Term Memory) networks can capture temporal dependencies.\n",
        "Here we reshape the data to use LSTM architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reshape data for LSTM (samples, timesteps, features)\n",
        "# We'll treat each feature as a timestep\n",
        "X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "print(f\"LSTM input shape: {X_train_lstm.shape}\")\n",
        "\n",
        "# Build LSTM model\n",
        "def build_lstm_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=input_shape, name='lstm_1'),\n",
        "        Dropout(0.3),\n",
        "        \n",
        "        LSTM(32, return_sequences=False, name='lstm_2'),\n",
        "        Dropout(0.3),\n",
        "        \n",
        "        Dense(16, activation='relu', name='hidden_1'),\n",
        "        Dropout(0.2),\n",
        "        \n",
        "        Dense(1, name='output')\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='mean_squared_error',\n",
        "        metrics=['mae', 'mse']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Create LSTM model\n",
        "lstm_model = build_lstm_model((X_train_lstm.shape[1], X_train_lstm.shape[2]))\n",
        "\n",
        "print(\"\\nLSTM Neural Network Architecture:\")\n",
        "lstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train LSTM\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training LSTM Neural Network...\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "history_lstm = lstm_model.fit(\n",
        "    X_train_lstm, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate LSTM\n",
        "y_pred_lstm = lstm_model.predict(X_test_lstm).flatten()\n",
        "\n",
        "mse_lstm = mean_squared_error(y_test, y_pred_lstm)\n",
        "rmse_lstm = np.sqrt(mse_lstm)\n",
        "mae_lstm = mean_absolute_error(y_test, y_pred_lstm)\n",
        "r2_lstm = r2_score(y_test, y_pred_lstm)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"LSTM Neural Network - Test Results\")\n",
        "print(\"=\"*50)\n",
        "print(f\"MSE: {mse_lstm:,.2f}\")\n",
        "print(f\"RMSE: {rmse_lstm:,.2f}\")\n",
        "print(f\"MAE: {mae_lstm:,.2f}\")\n",
        "print(f\"R¬≤ Score: {r2_lstm:.4f}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Comparison and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison dataframe\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['Simple NN', 'Deep NN', 'LSTM'],\n",
        "    'MSE': [mse_simple, mse_deep, mse_lstm],\n",
        "    'RMSE': [rmse_simple, rmse_deep, rmse_lstm],\n",
        "    'MAE': [mae_simple, mae_deep, mae_lstm],\n",
        "    'R¬≤ Score': [r2_simple, r2_deep, r2_lstm]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL COMPARISON - ALL NEURAL NETWORKS\")\n",
        "print(\"=\"*70)\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Find best model\n",
        "best_model_idx = results_df['R¬≤ Score'].idxmax()\n",
        "best_model_name = results_df.loc[best_model_idx, 'Model']\n",
        "best_r2 = results_df.loc[best_model_idx, 'R¬≤ Score']\n",
        "\n",
        "print(f\"\\nüèÜ BEST MODEL: {best_model_name} with R¬≤ = {best_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 1: Model Comparison Bar Chart\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# MSE Comparison\n",
        "axes[0, 0].bar(results_df['Model'], results_df['MSE'], color=['skyblue', 'lightgreen', 'lightcoral'])\n",
        "axes[0, 0].set_title('Mean Squared Error (Lower is Better)', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_ylabel('MSE')\n",
        "axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# RMSE Comparison\n",
        "axes[0, 1].bar(results_df['Model'], results_df['RMSE'], color=['skyblue', 'lightgreen', 'lightcoral'])\n",
        "axes[0, 1].set_title('Root Mean Squared Error (Lower is Better)', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_ylabel('RMSE')\n",
        "axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# MAE Comparison\n",
        "axes[1, 0].bar(results_df['Model'], results_df['MAE'], color=['skyblue', 'lightgreen', 'lightcoral'])\n",
        "axes[1, 0].set_title('Mean Absolute Error (Lower is Better)', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_ylabel('MAE')\n",
        "axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# R¬≤ Score Comparison\n",
        "axes[1, 1].bar(results_df['Model'], results_df['R¬≤ Score'], color=['skyblue', 'lightgreen', 'lightcoral'])\n",
        "axes[1, 1].set_title('R¬≤ Score (Higher is Better)', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_ylabel('R¬≤ Score')\n",
        "axes[1, 1].set_ylim([0, 1])\n",
        "axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 2: Training History (Loss over epochs)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Simple NN\n",
        "axes[0].plot(history_simple.history['loss'], label='Training Loss', linewidth=2)\n",
        "axes[0].plot(history_simple.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "axes[0].set_title('Simple NN - Training History', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss (MSE)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Deep NN\n",
        "axes[1].plot(history_deep.history['loss'], label='Training Loss', linewidth=2)\n",
        "axes[1].plot(history_deep.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "axes[1].set_title('Deep NN - Training History', fontsize=12, fontweight='bold')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Loss (MSE)')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "# LSTM\n",
        "axes[2].plot(history_lstm.history['loss'], label='Training Loss', linewidth=2)\n",
        "axes[2].plot(history_lstm.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "axes[2].set_title('LSTM - Training History', fontsize=12, fontweight='bold')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('Loss (MSE)')\n",
        "axes[2].legend()\n",
        "axes[2].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 3: Actual vs Predicted for all models\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Simple NN\n",
        "axes[0].scatter(y_test, y_pred_simple, alpha=0.5, s=20)\n",
        "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "axes[0].set_xlabel('Actual Wages')\n",
        "axes[0].set_ylabel('Predicted Wages')\n",
        "axes[0].set_title(f'Simple NN (R¬≤={r2_simple:.4f})', fontweight='bold')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Deep NN\n",
        "axes[1].scatter(y_test, y_pred_deep, alpha=0.5, s=20, color='green')\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "axes[1].set_xlabel('Actual Wages')\n",
        "axes[1].set_ylabel('Predicted Wages')\n",
        "axes[1].set_title(f'Deep NN (R¬≤={r2_deep:.4f})', fontweight='bold')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "# LSTM\n",
        "axes[2].scatter(y_test, y_pred_lstm, alpha=0.5, s=20, color='coral')\n",
        "axes[2].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "axes[2].set_xlabel('Actual Wages')\n",
        "axes[2].set_ylabel('Predicted Wages')\n",
        "axes[2].set_title(f'LSTM (R¬≤={r2_lstm:.4f})', fontweight='bold')\n",
        "axes[2].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Findings and Recommendations\n",
        "\n",
        "### Summary:\n",
        "1. **Model Performance**: All three neural network architectures were trained and evaluated\n",
        "2. **Best Model**: The model comparison shows which architecture works best for this dataset\n",
        "3. **Deep Learning Advantages**:\n",
        "   - Can capture non-linear relationships\n",
        "   - Automatically learns feature interactions\n",
        "   - Scalable to larger datasets\n",
        "\n",
        "### When to Use Each Model:\n",
        "- **Simple NN**: Good baseline, fast training, interpretable\n",
        "- **Deep NN**: Better for complex patterns, more data needed\n",
        "- **LSTM**: Best for sequential/temporal patterns\n",
        "\n",
        "### Next Steps:\n",
        "1. **Hyperparameter Tuning**: Adjust learning rate, batch size, neurons\n",
        "2. **Feature Engineering**: Create new features from existing ones\n",
        "3. **Ensemble Methods**: Combine predictions from multiple models\n",
        "4. **Cross-Validation**: Use k-fold CV for more robust evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model\n",
        "# Uncomment the line below to save\n",
        "# best_model.save('best_mgnrega_wage_prediction_model.h5')\n",
        "print(\"\\nTo save the model, uncomment the save line in this cell\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
